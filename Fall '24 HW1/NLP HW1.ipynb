{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fae08a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from corus import load_buriy_webhose\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import spacy\n",
    "import re\n",
    "import wget\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b940d0",
   "metadata": {},
   "source": [
    "# 1. Получение значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ffaa5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(txt): # функция очистки теста словарной статьи из wikitionary\n",
    "    text = re.sub(r'◆.+', '', txt)\n",
    "    text = re.sub(r'\\[[≈≠▲▼].+', '', text)\n",
    "    text = re.sub(r'^[а-яё]+\\. ', '', text)\n",
    "    text = re.sub(r'\\s', ' ', text)\n",
    "    text = re.sub(r' (?=[\\W])', '', text)\n",
    "    return re.sub(r' \\Z', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3da2d1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getmeanings(word): # функция автоматического получения значений из wikitionary для русского\n",
    "    bs = BeautifulSoup(requests.get(f'https://ru.wiktionary.org/wiki/{word.lower()}').text)\n",
    "    meanings = [clean(el.text) for el in bs.find('ol').find_all('li')]\n",
    "    return meanings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76febd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['куча', 'золото', 'волна', 'выход', 'лист'] # слова, с которыми я буду работать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acd21027",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexemes = {} # получение значений\n",
    "for word in words:\n",
    "    lexemes[word] = getmeanings(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d77155d",
   "metadata": {},
   "source": [
    "Посмотрим на получившиеся значения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9721fd8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'куча': ['большое количество чего-либо, обычно сыпучего, мелкого, наваленного, насыпанного в одном месте',\n",
       "  'беспорядочное скопление людей, животных, автомобилей и т. п.',\n",
       "  'большое количество чего-либо',\n",
       "  'структура данных в виде дерева или деревьев, где у каждого узла значение ключа не меньше(в другом варианте: не больше), чем значения ключей у узлов-потомков',\n",
       "  'область динамически распределяемой памяти'],\n",
       " 'золото': ['химический элемент с атомным номером 79, обозначается химическим символом Au',\n",
       "  'драгоценный металл жёлтого цвета',\n",
       "  'то, что цветом напоминает такой металл; золотой цвет, блеск чего-либо',\n",
       "  'нечто ценное',\n",
       "  'обращение к тому, кто дорог и любим',\n",
       "  'то же, что золотая медаль',\n",
       "  'денежный эквивалент'],\n",
       " 'волна': ['вал на поверхности водоёма при её колебании под действием ветра, сейсмических явлений, механического воздействия',\n",
       "  'изменение некоторой совокупности физических величин(характеристик некоторого физического поля или материальной среды), способное перемещаться, удаляясь от места их возникновения, или колебаться внутри ограниченных областей пространства',\n",
       "  'густой поток, массовый наплыв чего-либо',\n",
       "  'в механике сплошных сред элементарная составляющая колебаний на поверхности раздела между жидкостью и газом или жидкостью и жидкостью',\n",
       "  'гимнастический, танцевальный и т. п. элемент в виде волнообразного движения тела'],\n",
       " 'выход': ['действие по значению гл. выходить; перемещение вовне или за пределы чего-либо',\n",
       "  'место, где осуществляется такое действие',\n",
       "  'способ разрешения проблемы',\n",
       "  'количество произведённых продуктов(например, на производстве или в результате химической реакции)',\n",
       "  'момент появления кого-либо или чего-либо(например, артиста на сцене, книги, кинофильма, телевизионной передачи)',\n",
       "  'попадание на определённый этап конкурса или соревнования',\n",
       "  'силовой элемент на турнике, конечная цель которого— попадание в какой-либо упор'],\n",
       " 'лист': ['орган растения в виде тонкой пластинки, служащий для воздушного питания, газообмена и фотосинтеза',\n",
       "  'пласт, тонкий плоский слой',\n",
       "  'документ, бланк, удостоверение, формуляр']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexemes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257d702e",
   "metadata": {},
   "source": [
    "# 2. Отбор предложений из корпуса"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a2b959",
   "metadata": {},
   "source": [
    "## 2.1. Обработка корпуса"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f37e7",
   "metadata": {},
   "source": [
    "```python\n",
    "corpus = load_buriy_webhose('webhose-2016.tar.bz2') # подгрузка корпуса webhose\n",
    "\n",
    "nlp = spacy.load('ru_core_news_sm') # подгрузка модуля spacy\n",
    "\n",
    "examples = {word: [] for word in words} # словарь для примеров\n",
    "\n",
    "for article in tqdm(corpus, total=285965): # парсим статьи в корпусе\n",
    "    for sentence in sent_tokenize(article.text): # делим статьи на предложения\n",
    "        lemmas = [word.lemma_ for word in nlp(sentence)] # лемматизируем\n",
    "        i = 0\n",
    "        while i < len(words): # проходимся по таргетным словам\n",
    "            # добавляем предложение к примерам, если в нем присутствует таргетное слово\n",
    "            if words[i] in lemmas and sentence not in examples[words[i]]:  \n",
    "                examples[words[i]].append(sentence)\n",
    "                # если для слова уже набралось 200 примеров - больше не ищем для него примеры\n",
    "                if len(examples[words[i]]) == 200: \n",
    "                    words.pop(i)\n",
    "            i += 1\n",
    "    if len(words) == 0:\n",
    "        break\n",
    "\n",
    "words = ['куча', 'золото', 'волна', 'выход', 'лист']\n",
    "# записываем результат\n",
    "with open('examples.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(examples, f, ensure_ascii=False, indent='\\t')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f1c865",
   "metadata": {},
   "source": [
    "## 2.2. Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "295e58f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('examples.json', 'r', encoding='utf-8') as f: # читаем данные\n",
    "    examples = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa1f69b",
   "metadata": {},
   "source": [
    "Посмотрим на примеры истатистику:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "267c8521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "куча, примеров 101\n",
      "---\n",
      "Но тогда хозяева не использовали кучу моментов, сравняв счет лишь в концовке.\n",
      "Слушаешь, и начинаешь понимать – острее всех люди реагируют на, казалось бы, мелочи... \n",
      "Ну вот Дональд Трамп наговорил кучу страшнейших вещей - от изгнания мусульман до признания Крыма частью России.\n",
      "В ответ критики заявили, что тоже могут поехать США, посетить NASA в качестве туристов и наснимать кучу фотографий.\n",
      "\n",
      "\n",
      "золото, примеров 165\n",
      "---\n",
      "Фото: Архив пресс-службы Стивен Вебстер посвятил коллекцию гаданию на цветке В коллекцию Stephen Webster «Love Me, Love Me Not» вошли украшения из розового и белого золота, инкрустированные зеленым агатом в окружении черных бриллиантов и розовым опалом или гематитом с белыми бриллиантами.\n",
      "По словам министра, которые приводит агентство Рейтер, соглашение об ограничении добычи \"черного золота\" будет действовать до одного года.\n",
      "Goldman Sachs вычислил, когда завершится «нефтяное ралли» 6 Октября 2016, 20:18 \n",
      "Ралли на мировом нефтяном рынке закончится, когда цена на «черное золото» вырастет до $55 за баррель, поскольку тогда на рынок вновь вернутся сланцевые компании из США, заявили представители Goldman Sachs Group.\n",
      "\n",
      "\n",
      "волна, примеров 200\n",
      "---\n",
      "Обе организации сейчас активно работают в информационном пространстве над дискредитацией самого президента его блока и всех тех политиков, что пришли к власти на волне «революции достоинства».\n",
      "Российский лидер вернулся в \"Большую лигу\", явно переигрывает Обаму в Сирии, установил свои правила игры по Украине и с нескрываемым удовлетворением наблюдает за тем, как старушку Европу заливают волны мигрантов с Ближнего Востока и Северной Африки, как там растут ряды ультраправых партий, а Британия отчаливает от европейского континента в рамках своего Brexit.\n",
      "И объясняется этот факт очень просто: тогда народ наслаждался демократическими речами младшего научного сотрудника Станкевича, демократа первой волны (ставшего заместителем главы Москвы, бежавшего после того как он был обвинен в коррупции в Польшу, отсидевшегося где-то в заграницах и вот уже вновь объявившегося в Первопрестольной в качестве умеренного социал-демократа, умеренного ура-патриота и умеренного проамериканиста).\n",
      "\n",
      "\n",
      "выход, примеров 200\n",
      "---\n",
      "Европейский автопром гадает, что принесет ему выход Великобритании из Евросоюза.\n",
      "Софи Клоде, Еuronews: “Какими, на ваш взгляд, могут быть долгосрочные последствия выхода Британии из Евросоюза?”\n",
      "Андре Сапир: “Конечно же, обмен товарами и услугами между Британией и ЕС будет продолжаться.\n",
      "Факт выхода за пределы единого рынка и, возможно, отсутствие механизма “паспортизации” банковских операций приведут к немалым потерям для Великобритании”.\n",
      "\n",
      "\n",
      "лист, примеров 150\n",
      "---\n",
      "В шорт-лист категории «Лидерство» наряду с Эльханом Мамедовым были включены весьма значимые фигуры - президент известного спортивного издания Bleacher Report Рори Браун, глава Операционного комитета популярных соревнований по парусному спорту America's Cup Сэм Холлис, первый вице-президент и исполнительный продюсер телеканала ESPN Коннор Шелл, исполнительный директор футбольного клуба «Манчестер Сити» Омар Беррада, финансовый директор UFC (одной из самых популярных в мире организаций по боям без правил) Накиса Бидариан, а также глава Департамента профессионального футбола ФИФА Джеймс Джонсон.\n",
      "Ведь для того, чтобы собрать первый урожай чайного листа, понадобится 6, а то и 7 лет.\n",
      "А когда чайный лист вырастет и производство начнет себя окупать, фермер постепенно, из своей прибыли, вернет государству данный ему беспроцентный кредит.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for word, example_list in examples.items():\n",
    "    print(f'{word}, примеров {len(example_list)}', '---', *example_list[:3], sep='\\n')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2a9ca5",
   "metadata": {},
   "source": [
    "# 3. Классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5ba48b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizerFast\n",
    "from sklearn.cluster import KMeans\n",
    "from nltk.tokenize import word_tokenize \n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d839c8",
   "metadata": {},
   "source": [
    "## 3.1. Контекстные эмбеддинги"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c684953d",
   "metadata": {},
   "source": [
    "Подгружаю небольшую [модель](https://huggingface.co/setu4993/smaller-LaBSE) для создания эмбеддингов для предложений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d646c676",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"setu4993/smaller-LaBSE\")\n",
    "model = BertModel.from_pretrained(\"setu4993/smaller-LaBSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76718fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = {word: [] for word in words}\n",
    "\n",
    "for word, examples_list in examples.items(): # беру примеры для каждого слова\n",
    "    embeddings[word] = [] # создаю список эмбеддингов\n",
    "    for i in range(0, len(examples_list), 20): # делю примеры на батчи по 20 вхождений\n",
    "        tokenized = tokenizer(examples_list[i:i+20], return_tensors='pt', padding=True) # токенизирую примеры\n",
    "        embeddings[word].extend(model(**tokenized).pooler_output.tolist()) # получаю эмбеддинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a4c81a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "clustering = {}\n",
    "for word, emb in embeddings.items():\n",
    "    # кластеризую примеры методом KMeans, где k вдвое больше количества значений слова;\n",
    "    # евристика следующая: чем больше значений в словаре, тем больше возможных контекстов\n",
    "    clustering[word] = KMeans(len(lexemes[word])*2, random_state=0).fit(emb) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d434a8f0",
   "metadata": {},
   "source": [
    "## 3.2. TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a38f4f",
   "metadata": {},
   "source": [
    "Пробую кластеризацию по матрице TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73e9632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74a75474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('ru_core_news_sm') # подгрузка модуля spacy\n",
    "matrices = {word: {} for word in words}\n",
    "\n",
    "for word, examples_list in examples.items(): # беру примеры для каждого слова\n",
    "    # лемматизирую их\n",
    "    lemmatized = [' '.join([word.lemma_ for word in nlp(sentence)]) for sentence in examples_list]\n",
    "    \n",
    "    tfidf = TfidfVectorizer(tokenizer=lambda x: x.split()) # создаю токенизатор\n",
    "    matrices[word]['matrix'] = tfidf.fit_transform(lemmatized) # получаю матрицу для примеров\n",
    "    matrices[word]['vectorizer'] = tfidf # сохраняю токенизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cc3487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "clustering_tfidf = {}\n",
    "for word, val in matrices.items():\n",
    "    # кластеризую примеры методом KMeans, где k вдвое больше количества значений слова;\n",
    "    # евристика следующая: чем больше значений в словаре, тем больше возможных контекстов\n",
    "    clustering_tfidf[word] = KMeans(len(lexemes[word])*2, random_state=0).fit(val['matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4405e7f",
   "metadata": {},
   "source": [
    "# 4. Классификация словарных значений"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb731af",
   "metadata": {},
   "source": [
    "## 4.1. Контекстные эмбеддинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bfdb3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {}\n",
    "\n",
    "for word, meanings in lexemes.items(): # беру значения каждого слова\n",
    "    tokenized = tokenizer(meanings, return_tensors='pt', padding=True) # токенизирую их\n",
    "    emb = model(**tokenized).pooler_output.tolist() # получаю эмбеддинги\n",
    "    classes[word] = clustering[word].predict(emb) # кластеризую тем же способом, что и примеры для данного слова"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fe7078",
   "metadata": {},
   "source": [
    "Посмотрим на получившуюся классификацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a187583b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'куча': array([1, 6, 6, 1, 0]),\n",
       " 'золото': array([ 6,  8,  5,  5, 12, 12,  6]),\n",
       " 'волна': array([1, 9, 6, 5, 2]),\n",
       " 'выход': array([ 7,  7,  7,  7, 10, 10,  0]),\n",
       " 'лист': array([3, 3, 4])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2dbd43",
   "metadata": {},
   "source": [
    "## 4.2. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "051a98fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_tfidf = {}\n",
    "\n",
    "for word, meanings in lexemes.items(): # беру значения каждого слова\n",
    "    lemmatized = [' '.join([word.lemma_ for word in nlp(sentence)]) for sentence in meanings] # лемматизирую их\n",
    "    # получаю вектора тем же способом, что и для примеров с этим словом\n",
    "    vectors = matrices[word]['vectorizer'].transform(lemmatized)     \n",
    "    classes_tfidf[word] = clustering_tfidf[word].predict(vectors) # кластеризую тем же способом, что и примеры для данного слова"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398e2450",
   "metadata": {},
   "source": [
    "Посмотрим на получившуюся классификацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca502a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'куча': array([8, 0, 8, 8, 0]),\n",
       " 'золото': array([0, 3, 3, 3, 3, 3, 3]),\n",
       " 'волна': array([5, 9, 5, 6, 9]),\n",
       " 'выход': array([11,  7, 11, 11, 11,  4, 11]),\n",
       " 'лист': array([2, 3, 3])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c573362",
   "metadata": {},
   "source": [
    "# 5. Разметка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ebf774",
   "metadata": {},
   "source": [
    "Я решил взять те значения, которые в обеих классификациях попали в разные классы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4369fdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen = {'куча': [0, 1],\n",
    " 'золото': [0, 1],\n",
    " 'волна': [0, 2],\n",
    " 'выход': [3, 5, 6],\n",
    " 'лист': [0, 1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b46c073",
   "metadata": {},
   "source": [
    "## 5.1. Контекстные эмбеддинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9db67428",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {}\n",
    "for word, meanings in chosen.items(): # прохожусь по словам\n",
    "    out[word] = []\n",
    "    for meaning in meanings: # прохожусь по значениям\n",
    "        # получаю тескт для значения и номер класса, к которому относится значения\n",
    "        text, num = lexemes[word][meaning], classes[word][meaning] \n",
    "        examples_num = np.where(clustering[word].labels_ == num)[0][:5] # получаю индексы примеров из того же класса\n",
    "        examples_text = np.array(examples[word])[examples_num] # получаю примеры по индексам\n",
    "        out[word].append({'meaning': text, 'examples': examples_text.tolist()}) # добавляю в словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d08045d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['word', 'meaning', 'example', 'marker']) # формирую таблицу для разметки\n",
    "for word, meanings in out.items(): # прохожусь по словам\n",
    "    for meaning in meanings: # прохожусь по значениям\n",
    "        new = pd.DataFrame(meaning['examples'], columns=['example']) # создаю столбец с примерами\n",
    "        new['meaning'] = meaning['meaning'] # добавляю столбец со значением\n",
    "        new['word'] = word # добавляю столбец со словом\n",
    "        df = pd.concat((df, new)) # объединяю с общей таблицей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca6cabd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('tagging_1.xlsx') as wt: # записываю в файл\n",
    "    df.to_excel(wt, sheet_name='tagging', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d720993f",
   "metadata": {},
   "source": [
    "## 5.2. TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15e56e2",
   "metadata": {},
   "source": [
    "Здесь все аналогично"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2e4d2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tfidf = {}\n",
    "for word, meanings in chosen.items():\n",
    "    out_tfidf[word] = []\n",
    "    for meaning in meanings:\n",
    "        text, num = lexemes[word][meaning], classes_tfidf[word][meaning]\n",
    "        examples_num = np.where(clustering_tfidf[word].labels_ == num)[0][:5]\n",
    "        examples_text = np.array(examples[word])[examples_num]\n",
    "        out_tfidf[word].append({'meaning': text, 'examples': examples_text.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af978593",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf = pd.DataFrame(columns=['word', 'meaning', 'example', 'marker'])\n",
    "for word, meanings in out_tfidf.items():\n",
    "    for meaning in meanings:\n",
    "        new = pd.DataFrame(meaning['examples'], columns=['example'])\n",
    "        new['meaning'] = meaning['meaning']\n",
    "        new['word'] = word\n",
    "        df_tfidf = pd.concat((df_tfidf, new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dbd20515",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('tagging_2.xlsx') as wt:\n",
    "    df_tfidf.to_excel(wt, sheet_name='tagging', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b27992",
   "metadata": {},
   "source": [
    "# 6. Оценка качества"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727a7ed2",
   "metadata": {},
   "source": [
    "После ручной разметки можео подвести итоги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e06d4354",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_dl, accuracy_tfidf = pd.read_excel('tagging_1.xlsx').marker.mean(), pd.read_excel('tagging_2.xlsx').marker.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75177083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy на основе работы BERT модели составляет 0.21818181818181817\n",
      "Accuracy на основе матрицы TF-IDF составляет 0.21818181818181817\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy на основе работы BERT модели составляет {accuracy_dl}\\n'\n",
    "     f'Accuracy на основе матрицы TF-IDF составляет {accuracy_tfidf}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec36dff",
   "metadata": {},
   "source": [
    "# 7. Сравнение результатов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429f062f",
   "metadata": {},
   "source": [
    "В итоге значения accuracy получились одинаковыми, при этом распределение ошибок немного отличается:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b96cb515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>marker</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th>meaning</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">волна</th>\n",
       "      <th>вал на поверхности водоёма при её колебании под действием ветра, сейсмических явлений, механического воздействия</th>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>густой поток, массовый наплыв чего-либо</th>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">выход</th>\n",
       "      <th>количество произведённых продуктов(например, на производстве или в результате химической реакции)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>попадание на определённый этап конкурса или соревнования</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>силовой элемент на турнике, конечная цель которого— попадание в какой-либо упор</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">золото</th>\n",
       "      <th>драгоценный металл жёлтого цвета</th>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>химический элемент с атомным номером 79, обозначается химическим символом Au</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">куча</th>\n",
       "      <th>беспорядочное скопление людей, животных, автомобилей и т. п.</th>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>большое количество чего-либо, обычно сыпучего, мелкого, наваленного, насыпанного в одном месте</th>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">лист</th>\n",
       "      <th>орган растения в виде тонкой пластинки, служащий для воздушного питания, газообмена и фотосинтеза</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>пласт, тонкий плоский слой</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           marker\n",
       "word   meaning                                                   \n",
       "волна  вал на поверхности водоёма при её колебании под...     0.8\n",
       "       густой поток, массовый наплыв чего-либо                0.6\n",
       "выход  количество произведённых продуктов(например, на...     0.0\n",
       "       попадание на определённый этап конкурса или сор...     0.0\n",
       "       силовой элемент на турнике, конечная цель котор...     0.0\n",
       "золото драгоценный металл жёлтого цвета                       0.6\n",
       "       химический элемент с атомным номером 79, обозна...     0.0\n",
       "куча   беспорядочное скопление людей, животных, автомо...     0.2\n",
       "       большое количество чего-либо, обычно сыпучего, ...     0.2\n",
       "лист   орган растения в виде тонкой пластинки, служащи...     0.0\n",
       "       пласт, тонкий плоский слой                             0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_excel('tagging_1.xlsx').groupby(['word', 'meaning']).aggregate({'marker': np.mean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5af98d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>marker</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th>meaning</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">волна</th>\n",
       "      <th>вал на поверхности водоёма при её колебании под действием ветра, сейсмических явлений, механического воздействия</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>густой поток, массовый наплыв чего-либо</th>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">выход</th>\n",
       "      <th>количество произведённых продуктов(например, на производстве или в результате химической реакции)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>попадание на определённый этап конкурса или соревнования</th>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>силовой элемент на турнике, конечная цель которого— попадание в какой-либо упор</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">золото</th>\n",
       "      <th>драгоценный металл жёлтого цвета</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>химический элемент с атомным номером 79, обозначается химическим символом Au</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">куча</th>\n",
       "      <th>беспорядочное скопление людей, животных, автомобилей и т. п.</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>большое количество чего-либо, обычно сыпучего, мелкого, наваленного, насыпанного в одном месте</th>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">лист</th>\n",
       "      <th>орган растения в виде тонкой пластинки, служащий для воздушного питания, газообмена и фотосинтеза</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>пласт, тонкий плоский слой</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           marker\n",
       "word   meaning                                                   \n",
       "волна  вал на поверхности водоёма при её колебании под...     0.0\n",
       "       густой поток, массовый наплыв чего-либо                0.8\n",
       "выход  количество произведённых продуктов(например, на...     0.0\n",
       "       попадание на определённый этап конкурса или сор...     0.2\n",
       "       силовой элемент на турнике, конечная цель котор...     0.0\n",
       "золото драгоценный металл жёлтого цвета                       1.0\n",
       "       химический элемент с атомным номером 79, обозна...     0.0\n",
       "куча   беспорядочное скопление людей, животных, автомо...     0.0\n",
       "       большое количество чего-либо, обычно сыпучего, ...     0.4\n",
       "лист   орган растения в виде тонкой пластинки, служащи...     0.0\n",
       "       пласт, тонкий плоский слой                             0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_excel('tagging_2.xlsx').groupby(['word', 'meaning']).aggregate({'marker': np.mean})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30418897",
   "metadata": {},
   "source": [
    "Оба подхода не справились со значениями, которые являются довольно специфичными для той или иной области: **выход** (_силовой элемент на турнике_), **вызод** (_количество произведённых продуктов_), **золото** (_химический элемент_), а также со значениями, которые скорее были плохо представлены в примерах из-за специфики самого корпуса, как например приведённые здесь значения слова **лист** (а в корпусе в основном встречается значение _лист бумаги_)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a68f84",
   "metadata": {},
   "source": [
    "Качество подходов незначительно отличается друг от друга из-за того, что в конечном счёте у них похожий принцип: мы пытаемся вывести значение слова через его контекст, отличается лишь методология работы с контекстом. На мой взгляд, для более успешного решения задачи нужно больше сконцентрироваться самом слове, так как контекст целиком может быть чувствителен к другим вхождениям, даже если они напрямую не касаются нашего таргетного слова. Таким образом, в подходе с эмбеддингами нейросети более успешным решением было бы анализировать эмбеддинг таргетного слова в контексте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332cdd98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
